{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43478b01",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Time-Series Forecasting Tutorial on US Air Passengers Dataset\n",
    "\n",
    "This notebook is a **tutorial-style guide** to time-series forecasting using the classic **US Air Passengers** dataset.\n",
    "\n",
    "We will:\n",
    "\n",
    "- Load and explore a monthly passenger count dataset (`data/AirPassengers.csv`)\n",
    "- Split it into training and test sets (last 12 months as test)\n",
    "- Implement and compare **several forecasting methods** from:\n",
    "  - **Classical statistics**\n",
    "  - **Modern machine learning**\n",
    "  - **Deep learning**\n",
    "  - **Specialized time-series libraries**\n",
    "\n",
    "## ðŸ”§ Methods Covered\n",
    "\n",
    "**Statistical / Classical Methods**\n",
    "1. Simple Moving Average (SMA)\n",
    "2. Weighted Moving Average (WMA)\n",
    "3. Exponential Moving Average (EMA)\n",
    "4. ARIMA (via `pmdarima`)\n",
    "5. Prophet (additive model)\n",
    "\n",
    "**Machine Learning Methods**\n",
    "6. Random Forest (with lag features)\n",
    "7. XGBoost (with lag features)\n",
    "\n",
    "**Deep Learning**\n",
    "8. LSTM (sequence modeling with Keras/TensorFlow)\n",
    "\n",
    "At the end, we will:\n",
    "\n",
    "- Compute **RMSE** (Root Mean Squared Error) for each method\n",
    "- Build a **comparative table**\n",
    "- Plot a **bar chart** comparing their performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240bc40b",
   "metadata": {},
   "source": [
    "***\n",
    "### Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ab0b456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install scikit-learn statsmodels pmdarima prophet xgboost tensorflow\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pmdarima as pm\n",
    "from prophet import Prophet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1bee6ff",
   "metadata": {},
   "source": [
    "***\n",
    "### âœˆï¸ Load US Air Passengers Dataset\n",
    "\n",
    "This tutorial uses the **US Air Passengers dataset**, a classic benchmark in time-series analysis and forecasting.  \n",
    "The dataset is available on Kaggle:\n",
    "\n",
    "ðŸ“Œ **Source:** https://www.kaggle.com/datasets/brmil07/air-passengers-dataset\n",
    "\n",
    "\n",
    "#### ðŸ“Š About the Dataset\n",
    "\n",
    "The dataset contains **monthly totals of US airline passengers** from **January 1949 to December 1960**.  \n",
    "This corresponds to **144 consecutive monthly observations**, making it a univariate numeric time-series suitable for classical and modern forecasting models.\n",
    "\n",
    "ðŸ”¢ **Dataset Columns**\n",
    "- **Month** â€” Calendar month in the format `YYYY-MM`\n",
    "- **Passengers** â€” Number of airline passengers (in thousands)\n",
    "\n",
    "\n",
    "#### ðŸ“ˆ Why This Dataset Is Commonly Used\n",
    "\n",
    "The Air Passengers dataset is widely used in forecasting tutorials because it exhibits:\n",
    "\n",
    "âœ” Clear upward **trend**  \n",
    "Passenger numbers grow steadily over time due to post-war economic expansion and increased air travel.\n",
    "\n",
    "âœ” Strong **seasonality**  \n",
    "Peaks occur during summer months, indicating consistent yearly traveling patterns.\n",
    "\n",
    "âœ” Realistic **noise and variability**  \n",
    "It models real-world behavior better than synthetic data.\n",
    "\n",
    "âœ” Simplicity for teaching  \n",
    "It is small, easy to visualize, and ideal for demonstrating statistical, machine learning, and deep-learning forecasting methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac459c83",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m url = \u001b[33m\"\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/Dr-AlaaKhamis/ISE518/refs/heads/main/datasets/AirPassengers.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mShape:\u001b[39m\u001b[33m\"\u001b[39m, df.shape)\n\u001b[32m      4\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    725\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    727\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    730\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    731\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    732\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    733\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    736\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    737\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    383\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    385\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    283\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\urllib\\request.py:189\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, context)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    188\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\urllib\\request.py:495\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.process_response.get(protocol, []):\n\u001b[32m    494\u001b[39m     meth = \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     response = \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\urllib\\request.py:604\u001b[39m, in \u001b[36mHTTPErrorProcessor.http_response\u001b[39m\u001b[34m(self, request, response)\u001b[39m\n\u001b[32m    601\u001b[39m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[32m    602\u001b[39m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[32m    603\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[32m200\u001b[39m <= code < \u001b[32m300\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m604\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparent\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    605\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttp\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\urllib\\request.py:533\u001b[39m, in \u001b[36mOpenerDirector.error\u001b[39m\u001b[34m(self, proto, *args)\u001b[39m\n\u001b[32m    531\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[32m    532\u001b[39m     args = (\u001b[38;5;28mdict\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mhttp_error_default\u001b[39m\u001b[33m'\u001b[39m) + orig_args\n\u001b[32m--> \u001b[39m\u001b[32m533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\urllib\\request.py:466\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    465\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    468\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alaa.rashwan\\.conda\\envs\\agents\\Lib\\urllib\\request.py:613\u001b[39m, in \u001b[36mHTTPDefaultErrorHandler.http_error_default\u001b[39m\u001b[34m(self, req, fp, code, msg, hdrs)\u001b[39m\n\u001b[32m    612\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[32m--> \u001b[39m\u001b[32m613\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req.full_url, code, msg, hdrs, fp)\n",
      "\u001b[31mHTTPError\u001b[39m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/Dr-AlaaKhamis/ISE518/refs/heads/main/datasets/AirPassengers.csv\"\n",
    "df = pd.read_csv(url)\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653f796",
   "metadata": {},
   "source": [
    "## Preprocessing and Trainâ€“Test Split\n",
    "\n",
    "We:\n",
    "\n",
    "1. Convert the `Month` column to a `datetime` type.\n",
    "2. Set it as the index to obtain a proper time series.\n",
    "3. Rename the passenger column to `Passengers` for convenience.\n",
    "4. Split the data so that the **last 12 months** are used as the **test set** and the rest as training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d4e26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Month to datetime and set as index\n",
    "df['Month'] = pd.to_datetime(df['Month'])\n",
    "df = df.set_index('Month')\n",
    "\n",
    "# Rename column for clarity\n",
    "df.columns = ['Passengers']\n",
    "\n",
    "# Basic plot\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(df['Passengers'])\n",
    "plt.title('US Air Passengers Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Passengers')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Trainâ€“test split: last 12 months as test\n",
    "train = df.iloc[:-12]\n",
    "test = df.iloc[-12:]\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "train.tail(), test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db099720",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "all_forecasts = {}  # to optionally store forecast series for plotting if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b2b44d",
   "metadata": {},
   "source": [
    "### Simple Moving Average (SMA)\n",
    "\n",
    "**Idea:**  \n",
    "The Simple Moving Average (SMA) forecasts future values by taking the **unweighted mean of the last *k* observations**.\n",
    "\n",
    "For example, a 12-month SMA uses the last 12 months of passenger counts and averages them to produce a forecast.\n",
    "\n",
    "**Formula:**  \n",
    "\n",
    "$\\text{SMA}_t = \\frac{1}{k} \\sum_{i=0}^{k-1} y_{t-i}$\n",
    "\n",
    "**Pros:**\n",
    "- Very easy to implement and explain.\n",
    "- Useful for smoothing noisy data.\n",
    "\n",
    "**Cons:**\n",
    "- Ignores trend and seasonality.\n",
    "- All points in the window are weighted equally (no recency preference).\n",
    "- Poor for complex, non-stationary series like AirPassengers.\n",
    "\n",
    "We will use a **12-month window** and then use the **last SMA value** as a constant forecast for the next 12 months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1e0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 12\n",
    "\n",
    "# Rolling mean over the training data\n",
    "sma_series = train['Passengers'].rolling(window=window).mean()\n",
    "\n",
    "# Use the last available SMA value as forecast for all 12 future months\n",
    "last_sma = sma_series.iloc[-1]\n",
    "sma_forecast = np.repeat(last_sma, len(test))\n",
    "\n",
    "rmse_sma = np.sqrt(mean_squared_error(test['Passengers'], sma_forecast))\n",
    "results['SMA'] = rmse_sma\n",
    "all_forecasts['SMA'] = sma_forecast\n",
    "\n",
    "print('SMA RMSE:', rmse_sma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad64ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"SMA\"], label=\"SMA Forecast\", color=\"red\", linewidth=3)\n",
    "plt.title(\"Simple Moving Average Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6e6a1c",
   "metadata": {},
   "source": [
    "### Weighted Moving Average (WMA)\n",
    "\n",
    "**Idea:**  \n",
    "The Weighted Moving Average (WMA) is similar to SMA, but assigns **more weight to recent observations**.\n",
    "\n",
    "For a 12-point WMA, we might assign weights: 1, 2, 3, ..., 12, giving the most recent month the highest weight.\n",
    "\n",
    "**Formula:**  \n",
    "\n",
    "$\\text{WMA}_t = \\frac{\\sum_{i=0}^{k-1} w_i y_{t-i}}{\\sum_{i=0}^{k-1} w_i}$\n",
    "\n",
    "Where $ w_i $ are weights (larger for recent data).\n",
    "\n",
    "**Pros:**\n",
    "- Emphasizes recent patterns.\n",
    "- Still simple and fast.\n",
    "\n",
    "**Cons:**\n",
    "- Does not explicitly model trend or seasonality.\n",
    "- Choice of weights is heuristic.\n",
    "\n",
    "We choose linear weights from 1 to 12, with the highest weight on the most recent month.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bb40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define linear weights for the last 12 months\n",
    "window = 12\n",
    "weights = np.arange(1, window + 1)\n",
    "\n",
    "# Take last 12 points of the training set\n",
    "last_12 = train['Passengers'].iloc[-window:].values\n",
    "\n",
    "# Compute weighted average\n",
    "wma_value = np.sum(last_12 * weights) / np.sum(weights)\n",
    "\n",
    "wma_forecast = np.repeat(wma_value, len(test))\n",
    "\n",
    "rmse_wma = np.sqrt(mean_squared_error(test['Passengers'], wma_forecast))\n",
    "results['WMA'] = rmse_wma\n",
    "all_forecasts['WMA'] = wma_forecast\n",
    "\n",
    "print('WMA RMSE:', rmse_wma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d23a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], color=\"black\", label=\"Historical\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"WMA\"], label=\"WMA Forecast\", color=\"green\", linewidth=3)\n",
    "plt.title(\"Weighted Moving Average Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a438d06",
   "metadata": {},
   "source": [
    "### Exponential Moving Average (EMA)\n",
    "\n",
    "**Idea:**  \n",
    "The Exponential Moving Average (EMA) assigns **exponentially decaying weights** to past observations, so recent data has much higher influence than older data.\n",
    "\n",
    "Unlike SMA/WMA, EMA reacts more quickly to level shifts.\n",
    "\n",
    "**Formula (recursive form):**  \n",
    "\n",
    "$\n",
    "EMA_t = \\alpha y_t + (1 - \\alpha) EMA_{t-1}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ 0 < \\alpha < 1 $ is the smoothing factor.\n",
    "\n",
    "**Pros:**\n",
    "- More responsive to level changes than SMA.\n",
    "- Still simple, used heavily in finance and monitoring.\n",
    "\n",
    "**Cons:**\n",
    "- Does not explicitly model trend or seasonality.\n",
    "- Choice of $ \\alpha $ (or span) is heuristic.\n",
    "\n",
    "We will compute a 12-period EMA on the training data and use its **last value** to forecast the next 12 months.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb339d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "span = 12  # roughly similar to 12-month window\n",
    "ema_series = train['Passengers'].ewm(span=span, adjust=False).mean()\n",
    "last_ema = ema_series.iloc[-1]\n",
    "\n",
    "ema_forecast = np.repeat(last_ema, len(test))\n",
    "\n",
    "rmse_ema = np.sqrt(mean_squared_error(test['Passengers'], ema_forecast))\n",
    "results['EMA'] = rmse_ema\n",
    "all_forecasts['EMA'] = ema_forecast\n",
    "\n",
    "print('EMA RMSE:', rmse_ema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9679b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"EMA\"], label=\"EMA Forecast\", color=\"purple\", linewidth=3)\n",
    "plt.title(\"Exponential Moving Average Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf173eeb",
   "metadata": {},
   "source": [
    "### ARIMA (Autoregressive Integrated Moving Average)\n",
    "\n",
    "**Idea:**  \n",
    "ARIMA is a classical time-series model that combines:\n",
    "\n",
    "- **AR (Autoregressive):** past values (lags of the series)\n",
    "- **I (Integrated):** differencing to remove trend\n",
    "- **MA (Moving Average):** past forecast errors\n",
    "\n",
    "An ARIMA(p, d, q) model is defined by:\n",
    "- $ p $: autoregressive order\n",
    "- $ d $: degree of differencing\n",
    "- $ q $: moving average order\n",
    "\n",
    "We will use **`pmdarima.auto_arima`** to automatically select good (p, d, q) and seasonal parameters.\n",
    "\n",
    "**Pros:**\n",
    "- Strong for linear, stationary(ish) time series with clear autocorrelation.\n",
    "- Well-understood, interpretable.\n",
    "\n",
    "**Cons:**\n",
    "- Struggles with strong non-linearity.\n",
    "- Manual order selection can be tedious (auto_arima helps).\n",
    "- Seasonality must be modeled explicitly (SARIMA).\n",
    "\n",
    "If `pmdarima` is not installed, this cell will skip and print a message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fb869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AirPassengers has strong monthly seasonality, so we use seasonal=True, m=12\n",
    "y_train = train['Passengers']\n",
    "\n",
    "model_arima = pm.auto_arima(\n",
    "    y_train,\n",
    "    seasonal=True,\n",
    "    m=12,\n",
    "    stepwise=True,\n",
    "    suppress_warnings=True,\n",
    "    error_action='ignore'\n",
    ")\n",
    "\n",
    "print('Selected ARIMA order:', model_arima.order)\n",
    "print('Selected seasonal order:', model_arima.seasonal_order)\n",
    "\n",
    "arima_forecast = model_arima.predict(n_periods=len(test))\n",
    "\n",
    "rmse_arima = np.sqrt(mean_squared_error(test['Passengers'], arima_forecast))\n",
    "results['ARIMA'] = rmse_arima\n",
    "all_forecasts['ARIMA'] = arima_forecast\n",
    "\n",
    "print('ARIMA RMSE:', rmse_arima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fffa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"ARIMA\"], label=\"ARIMA Forecast\", color=\"orange\", linewidth=3)\n",
    "plt.title(\"ARIMA Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f80de2c",
   "metadata": {},
   "source": [
    "### Prophet (Additive Time-Series Model by Meta)\n",
    "\n",
    "**Idea:**  \n",
    "Prophet is a model developed by Meta (Facebook) designed for **business time series** with:\n",
    "\n",
    "- Trend\n",
    "- Multiple seasonalities (daily, weekly, yearly)\n",
    "- Holiday effects\n",
    "\n",
    "It uses an **additive decomposition model**:\n",
    "\n",
    "$\n",
    "y(t) = g(t) + s(t) + h(t) + \\epsilon_t\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $ g(t) $: trend (piecewise linear or logistic)\n",
    "- $ s(t) $: seasonality (Fourier series)\n",
    "- $ h(t) $: holiday effects\n",
    "- $ \\epsilon_t $: noise\n",
    "\n",
    "**Pros:**\n",
    "- Easy to use, robust to missing data and outliers.\n",
    "- Automatically handles trend and yearly seasonality.\n",
    "- Great for many applied forecasting tasks.\n",
    "\n",
    "**Cons:**\n",
    "- Less flexible for highly irregular patterns.\n",
    "- May be overkill for simple series.\n",
    "\n",
    "If `prophet` is not installed, this section will be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0ea19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data in Prophet format: ds (date), y (value)\n",
    "df_prophet = df.reset_index().rename(columns={'Month': 'ds', 'Passengers': 'y'})\n",
    "train_prophet = df_prophet.iloc[:-12]\n",
    "test_prophet = df_prophet.iloc[-12:]\n",
    "\n",
    "m = Prophet()\n",
    "m.fit(train_prophet)\n",
    "\n",
    "future = m.make_future_dataframe(periods=12, freq='M')\n",
    "forecast = m.predict(future)\n",
    "\n",
    "# Extract predictions for the test period\n",
    "prophet_forecast = forecast.iloc[-12:]['yhat'].values\n",
    "\n",
    "rmse_prophet = np.sqrt(mean_squared_error(test_prophet['y'], prophet_forecast))\n",
    "results['Prophet'] = rmse_prophet\n",
    "all_forecasts['Prophet'] = prophet_forecast\n",
    "\n",
    "print('Prophet RMSE:', rmse_prophet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c74f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"Prophet\"], label=\"Prophet Forecast\", color=\"brown\", linewidth=3)\n",
    "plt.title(\"Prophet Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75275c1",
   "metadata": {},
   "source": [
    "### Random Forest with Lag Features\n",
    "\n",
    "**Idea:**  \n",
    "Random Forest is a tree-based ensemble method from machine learning. It is **not inherently time-series aware**, so we convert the series into a **supervised learning problem** by creating **lag features**.\n",
    "\n",
    "Example:\n",
    "- Input features: $ [y_{t-1}, y_{t-2}, ..., y_{t-12}] $\n",
    "- Target: $ y_t $\n",
    "\n",
    "We then train `RandomForestRegressor` to predict $ y_t $ from the lagged values.\n",
    "\n",
    "**Pros:**\n",
    "- Captures non-linear relationships.\n",
    "- Naturally handles interactions between lags.\n",
    "\n",
    "**Cons:**\n",
    "- Ignores strict time-series structure (e.g., autocorrelation across residuals).\n",
    "- Requires careful feature engineering (lags, rolling stats).\n",
    "\n",
    "If `sklearn`'s RandomForestRegressor is not available, this section will be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba65107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_lag_features(series, n_lags=12):\n",
    "    data = pd.DataFrame({'y': series})\n",
    "    for lag in range(1, n_lags + 1):\n",
    "        data[f'lag_{lag}'] = data['y'].shift(lag)\n",
    "    data = data.dropna()\n",
    "    return data\n",
    "\n",
    "lagged = make_lag_features(df['Passengers'], n_lags=12)\n",
    "\n",
    "# Align train/test based on time index\n",
    "# Last 12 rows of original series correspond to test period\n",
    "# So we split lagged data so that last 12 rows are test\n",
    "X = lagged.drop('y', axis=1)\n",
    "y = lagged['y']\n",
    "\n",
    "X_train_rf = X.iloc[:-12]\n",
    "X_test_rf = X.iloc[-12:]\n",
    "y_train_rf = y.iloc[:-12]\n",
    "y_test_rf = y.iloc[-12:]\n",
    "\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "rf.fit(X_train_rf, y_train_rf)\n",
    "rf_preds = rf.predict(X_test_rf)\n",
    "\n",
    "rmse_rf = np.sqrt(mean_squared_error(y_test_rf, rf_preds))\n",
    "results['RandomForest'] = rmse_rf\n",
    "all_forecasts['RandomForest'] = rf_preds\n",
    "\n",
    "print('Random Forest RMSE:', rmse_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52807dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"RandomForest\"], label=\"RF Forecast\", color=\"cyan\", linewidth=3)\n",
    "plt.title(\"Random Forest Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d114bf4",
   "metadata": {},
   "source": [
    "### XGBoost with Lag Features\n",
    "\n",
    "**Idea:**  \n",
    "XGBoost is a powerful gradient-boosted tree ensemble. Like Random Forest, it does not know about time by default, so we again use **lag features**.\n",
    "\n",
    "We reuse the same lagged dataset prepared earlier and train an `XGBRegressor` model.\n",
    "\n",
    "**Pros:**\n",
    "- Often very strong performance on tabular data.\n",
    "- Can capture complex non-linear patterns.\n",
    "\n",
    "**Cons:**\n",
    "- Needs hyperparameter tuning for best performance.\n",
    "- Still relies on manual feature engineering for time-series structure.\n",
    "\n",
    "If `xgboost` is not installed, this section will be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af7a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reuse X_train_rf, X_test_rf, y_train_rf, y_test_rf from above (lagged data)\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train_rf, y_train_rf)\n",
    "xgb_preds = xgb.predict(X_test_rf)\n",
    "\n",
    "rmse_xgb = np.sqrt(mean_squared_error(y_test_rf, xgb_preds))\n",
    "results['XGBoost'] = rmse_xgb\n",
    "all_forecasts['XGBoost'] = xgb_preds\n",
    "\n",
    "print('XGBoost RMSE:', rmse_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c07c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"XGBoost\"], label=\"XGBoost Forecast\", color=\"magenta\", linewidth=3)\n",
    "plt.title(\"XGBoost Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f771e1d",
   "metadata": {},
   "source": [
    "### LSTM (Long Short-Term Memory Network)\n",
    "\n",
    "**Idea:**  \n",
    "LSTM is a type of Recurrent Neural Network (RNN) designed to capture **long-term dependencies** using gating mechanisms. It is well-suited to **sequence modeling**, including time-series forecasting.\n",
    "\n",
    "We frame forecasting as:\n",
    "\n",
    "- Input: last 12 months of passenger counts (sequence of length 12)\n",
    "- Output: passenger count in the next month\n",
    "\n",
    "We will:\n",
    "\n",
    "1. Scale the series to [0, 1] for stable training.\n",
    "2. Create supervised sequences:\n",
    "\n",
    "$\n",
    "X^{(i)} = [y_{i-12}, ..., y_{i-1}], \\quad y^{(i)} = y_i\n",
    "$\n",
    "\n",
    "3. Train an LSTM on the training sequences.\n",
    "4. Evaluate on the last 12 months (test period) using the corresponding input windows.\n",
    "\n",
    "**Pros:**\n",
    "- Learns non-linear temporal patterns.\n",
    "- Handles longer-range dependencies better than simple RNN.\n",
    "\n",
    "**Cons:**\n",
    "- More complex, needs more data and tuning.\n",
    "- Sensitive to scaling and architecture choices.\n",
    "\n",
    "If TensorFlow/Keras is not installed, this section will be skipped.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35b7f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. Prepare data\n",
    "# ==========================================\n",
    "series = df['Passengers'].values.reshape(-1, 1)\n",
    "n_total = len(series)\n",
    "n_test = 12\n",
    "n_train = n_total - n_test\n",
    "\n",
    "# Scale using only the training portion\n",
    "scaler = MinMaxScaler()\n",
    "series_train_scaled = scaler.fit_transform(series[:n_train])\n",
    "series_all_scaled = scaler.transform(series)\n",
    "\n",
    "# ==========================================\n",
    "# 2. Create sequences\n",
    "# ==========================================\n",
    "def create_lstm_sequences(data_scaled, n_lags=12):\n",
    "    X_list, y_list = [], []\n",
    "    for i in range(n_lags, len(data_scaled)):\n",
    "        X_list.append(data_scaled[i-n_lags:i, 0])   # 12 values\n",
    "        y_list.append(data_scaled[i, 0])            # next value\n",
    "    return np.array(X_list), np.array(y_list)\n",
    "\n",
    "# Full supervised dataset\n",
    "X_all, y_all = create_lstm_sequences(series_all_scaled, n_lags=12)\n",
    "\n",
    "# Proper train-test split\n",
    "X_train_lstm = X_all[:-12]\n",
    "X_test_lstm  = X_all[-12:]\n",
    "\n",
    "y_train_lstm = y_all[:-12]\n",
    "y_test_lstm  = y_all[-12:]\n",
    "\n",
    "# Reshape for LSTM\n",
    "X_train_lstm = X_train_lstm.reshape(-1, 12, 1)\n",
    "X_test_lstm  = X_test_lstm.reshape(-1, 12, 1)\n",
    "\n",
    "print(\"TRAIN SAMPLES:\", X_train_lstm.shape)\n",
    "print(\"TEST SAMPLES :\", X_test_lstm.shape)\n",
    "\n",
    "# ==========================================\n",
    "# 3. Build LSTM model\n",
    "# ==========================================\n",
    "model_lstm = models.Sequential([\n",
    "    layers.LSTM(64, activation='tanh', return_sequences=False, input_shape=(12,1)),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# ==========================================\n",
    "# 4. Train LSTM (NOW WITH MULTIPLE EPOCHS)\n",
    "# ==========================================\n",
    "history = model_lstm.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    epochs=50,              # More epochs\n",
    "    batch_size=4,           # Smaller batch size â†’ more steps/epoch\n",
    "    verbose=1,              # Show epochs\n",
    "    validation_split=0.1\n",
    ")\n",
    "\n",
    "# ==========================================\n",
    "# 5. Forecast\n",
    "# ==========================================\n",
    "lstm_preds_scaled = model_lstm.predict(X_test_lstm).flatten()\n",
    "\n",
    "# inverse scale\n",
    "lstm_preds = scaler.inverse_transform(lstm_preds_scaled.reshape(-1,1)).flatten()\n",
    "y_test_true = series[n_train:]  # true last 12 months\n",
    "\n",
    "# ==========================================\n",
    "# 6. RMSE\n",
    "# ==========================================\n",
    "rmse_lstm = np.sqrt(mean_squared_error(y_test_true, lstm_preds))\n",
    "results['LSTM'] = rmse_lstm\n",
    "all_forecasts['LSTM'] = lstm_preds\n",
    "\n",
    "print(\"ðŸ”¥ LSTM RMSE:\", rmse_lstm)\n",
    "\n",
    "# ==========================================\n",
    "# 7. Plot loss curve\n",
    "# ==========================================\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('LSTM Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fb170",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\")\n",
    "plt.plot(test.index, test[\"Passengers\"], label=\"Actual Test\", color=\"blue\")\n",
    "plt.plot(test.index, all_forecasts[\"LSTM\"], label=\"LSTM Forecast\", color=\"darkred\", linewidth=3)\n",
    "plt.title(\"LSTM Forecast\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Passengers\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd817db",
   "metadata": {},
   "source": [
    "### Comparison of All Methods (RMSE)\n",
    "\n",
    "We now summarize the performance of all implemented methods using **RMSE** on the last 12 months of the series.\n",
    "\n",
    "Lower RMSE indicates better forecasting accuracy on this test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ee99f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a DataFrame from the results dict\n",
    "results_df = pd.DataFrame(\n",
    "    [{'Method': k, 'RMSE': v} for k, v in results.items()]\n",
    ").sort_values('RMSE')\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dddc782",
   "metadata": {},
   "source": [
    "### RMSE Comparison Plot\n",
    "\n",
    "The bar chart below visualizes the RMSE of each forecasting method for easier comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97580c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(results_df['Method'], results_df['RMSE'])\n",
    "plt.ylabel('RMSE')\n",
    "plt.title('Forecasting Method RMSE Comparison (Lower is Better)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4076d49",
   "metadata": {},
   "source": [
    "### Visual Comparison of Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec613ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14,6))\n",
    "\n",
    "# Plot full historical time series\n",
    "plt.plot(df.index, df[\"Passengers\"], label=\"Historical\", color=\"black\", linewidth=2)\n",
    "\n",
    "methods_to_plot = list(all_forecasts.keys())\n",
    "colors = plt.cm.tab20(np.linspace(0, 1, len(methods_to_plot)))\n",
    "\n",
    "# Plot each method's forecast on the test period\n",
    "for method, color in zip(methods_to_plot, colors):\n",
    "    forecast = all_forecasts[method]\n",
    "\n",
    "    # Ensure forecast length matches test set\n",
    "    forecast = np.array(forecast).flatten()\n",
    "    \n",
    "    plt.plot(\n",
    "        test.index,\n",
    "        forecast,\n",
    "        label=method,\n",
    "        linewidth=2,\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "plt.title(\"Forecast Comparison Across All Methods\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Number of Passengers\")\n",
    "plt.grid(True)\n",
    "plt.legend(loc=\"upper left\", bbox_to_anchor=(1,1))  # place legend outside\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
